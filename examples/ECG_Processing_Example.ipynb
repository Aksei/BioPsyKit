{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Processing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "This example notebook illustrates how to import and process ECG data per subject and save intermediate processing results so that further analysis can be performed (e.g., in <code>ECG_Analysis_Example.ipynb</code> or in <code>MIST_TSST_Example.ipynb</code>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import biopsykit as bp\n",
    "import biopsykit.signals.ecg as ecg\n",
    "from biopsykit.signals.ecg import EcgProcessor\n",
    "import biopsykit.utils.array_handling as array_handling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.rcParams['figure.figsize'] = (10,5)\n",
    "sns.set(style='ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: 1 Dataset, 1 Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example assumes that we have one dataset with only one phase, i.e. the dataset does not need to be split into multiple parts internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data, sampling_rate = bp.example_data.get_ecg_example()\n",
    "ep = EcgProcessor(df=ecg_data, sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process ECG Signal\n",
    "Calling `ep.ecg_process()` will perform R peak detection and perform outlier correcrtion with the default outlier correction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.ecg_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Use other outlier correction parameters\n",
    "Calling `ep.outlier_params_default()` will list available outlier correction parameters and their default parameter. See the doumentation of `ep.outlier_corrections()` for further information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available outlier correction parameters and their default parameter. See the doumentation of 'EcgProcessor.outlier_corrections()' for further information.\n",
    "# print(ep.outlier_params_default())\n",
    "# ep.ecg_process(outlier_correction=['statistical_rr', 'statistical_rr_diff', 'physiological'], outlier_params={'statistical_rr': 2.576, 'statistical_rr_diff': 1.96, 'physiological': (50, 180)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ECG and Heart Rate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ep.ecg_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get heart rate and print resulting heart rate \n",
    "hr_data = ep.heart_rate['Data']\n",
    "hr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an overview of the acquired data\n",
    "fig, axs = ecg.plotting.ecg_plot(ep, key='Data', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute HRV\n",
    "Heart rate variability (HRV) is computed over the complete interval. If you want to compute HRV over different subintervals, you need to split the data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep.hrv_process(ep, 'Data', index='Vp01', index_name=\"subject_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot HRVÂ Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = ecg.plotting.hrv_plot(ep, 'Data', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: 1 Dataset, Multiple Phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates the pipeline for one single dataset which contains data from multiple phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data, sampling_rate = bp.example_data.get_ecg_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we use the example ECG Data and assume we want to split it into 3 phases (names: Preparation, Stress, Recovery) of 3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide list of edge times (start times of the phases and the total end time)\n",
    "time_intervals = pd.Series([\"12:32\", \"12:35\", \"12:38\", \"12:41\"], index=[\"Preparation\", \"Stress\", \"Recovery\", \"End\"])\n",
    "# alternatively: provide dict with start-end times and names per phase\n",
    "#time_intervals = {\"Preparation\": (\"12:32\", \"12:35\"), \"Stress\": (\"12:35\", \"12:38\"), \"Recovery\": (\"12:38\", \"12:41\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = EcgProcessor(df=ecg_data, sampling_rate=sampling_rate, time_intervals=time_intervals)\n",
    "ep.ecg_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute HRV parameters for each Phase\n",
    "Using List Comprehension (calling `EcgProcessor.hrv_process()` for each phase) and concat the results into one dataframe using `pd.concat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_result = pd.concat([ep.hrv_process(ep, key=key, index=key) for key in ep.phases])\n",
    "# alternatively: call EcgProcessor.hrv_batch_process()\n",
    "# hrv_result = ep.hrv_batch_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot one Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = ecg.plotting.ecg_plot(ep, key='Stress', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = ecg.plotting.hrv_plot(ep, key='Stress', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Multiple Subjects, Multiple Phases per Recording (Example Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_data, sampling_rate = bp.example_data.get_ecg_example()\n",
    "ecg_data_02, sampling_rate = bp.example_data.get_ecg_example_02()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we use two ECG example datasets, where the last phase (\"Recovery\") differs in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dict = {\n",
    "    'Vp01': {\n",
    "        'Data': ecg_data, \n",
    "        'Time': pd.Series([\"12:32\", \"12:35\", \"12:38\", \"12:41\"], index=[\"Preparation\", \"Stress\", \"Recovery\", \"End\"])\n",
    "    }, \n",
    "    'Vp02': {\n",
    "        'Data': ecg_data_02,\n",
    "        # The last phase of Vp02 has a length of only 1 minute to demonstrate the functionality of cutting to equal length\n",
    "        'Time': pd.Series([\"12:55\", \"12:58\", \"13:01\", \"13:02\"], index=[\"Preparation\", \"Stress\", \"Recovery\", \"End\"])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # to visualize for-loop progress\n",
    "\n",
    "# dicionaries to store processing results\n",
    "dict_hr_subjects = {}\n",
    "dict_hrv_result = {}\n",
    "\n",
    "for subject_id, data_dict in tqdm(subject_dict.items(), desc=\"Subjects\"):\n",
    "    \n",
    "    ep = EcgProcessor(df=data_dict['Data'], time_intervals=data_dict['Time'], sampling_rate=sampling_rate)\n",
    "    ep.ecg_process(title=subject_id)\n",
    "    \n",
    "    dict_hr_subjects[subject_id] = ep.heart_rate\n",
    "    \n",
    "    hrv_result = ep.hrv_batch_process()\n",
    "    dict_hrv_result[subject_id] = hrv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### For the further steps of the Processing Pipeline, please refer to **Example 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Multiple Subjects, Multiple Phases per Recording (Batch Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example illustrates how to set up a proper data analysis pipeline to process multiple subjects in a loop. It consists of the following steps:\n",
    "1. **Get Time Information**: Load Excel sheet with time information (to process multiple subjects in a loop)\n",
    "1. **Query Data**: Iterate through a folder and search for all files with a specific file pattern  \n",
    "    *optional*: Iterate through a folder that contains *subfolders* for each subjects where data is stored  \n",
    "    *optional*: Extract Subject ID either from data filename or from folder name\n",
    "    1. Load ECG Dataset, split into phases based on time information from Excel sheet\n",
    "    1. Perform ECG processing with outlier correction\n",
    "    1. Compute HR, HRV, ... parameters per subject and phase\n",
    "1. **Store and Export Intermediate Results**: Store Heart Rate processing results in *HR subject dict* (nested dict containing results of all subjects) and export Heart Rate processing results per subject (as Excel files)\n",
    "1. **Interpolate and Resample Data**: all Heart Rate data is resampled to 1 Hz  \n",
    "    *optional*: Cut phase of each subject to the shortest duration  \n",
    "1. **Normalize Data** (*optional*): Normalize Heart Rate data with respect to the mean Heart Rate of the first phase (*Baseline*)\n",
    "1. **Rearrange Data** Data from *HR subject dict* is rearranged so that data of subjects is in one dataframe per phase for all subjects (denoted as *Phase dict*)\n",
    "1. **Export Result Parameter**: Export *Phase dict* as Excel file and Export ECG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Time Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time log file\n",
    "timelog_path = Path(\"../example_data/ecg_time_log.xlsx\")\n",
    "\n",
    "df_time_log = bp.io.load_time_log(timelog_path, index_cols=[\"ID\", \"Condition\"])\n",
    "df_time_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_base_path = Path(\"../example_data/ecg\")\n",
    "file_list = list(sorted(ecg_base_path.glob(\"*.bin\")))\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # to visualize for-loop progress\n",
    "\n",
    "# dicionaries to store processing results\n",
    "dict_hr_subjects = {}\n",
    "dict_hrv_result = {}\n",
    "\n",
    "# for loop to iterate though subjects\n",
    "for file_path in tqdm(file_list, desc=\"Subjects\"):\n",
    "    # optional: extract Subject ID from file name; multiple ways, e.g. using regex or by splitting the filename string\n",
    "    subject_id = file_path.name.split('.')[0].split('_')[-1]\n",
    "    \n",
    "    # optional: if data is stored in subfolders: additional .glob() on file_path, get subject_id from folder name\n",
    "    # ecg_files = list(sorted(file_path.glob(\"*\")))\n",
    "    # subject_id = file_path.name\n",
    "    \n",
    "    # check if folder contains data\n",
    "    # if len(ecg_files) == 0:\n",
    "        # print(\"No data for subject {}.\".format(subject_id))\n",
    "    \n",
    "    # the next step depends on the file structure:\n",
    "    # if you only have one recording per subject: load this file\n",
    "    # df, fs = bp.io.load_dataset_nilspod(ecg_files[0])\n",
    "    # if you have more than one recording per subject: loop through them, load the files and e.g. put them into a dictionary\n",
    "    \n",
    "    # load dataset\n",
    "    df, fs = bp.io.nilspod.load_dataset_nilspod(file_path)\n",
    "    \n",
    "    ep = EcgProcessor(df=df, time_intervals=df_time_log.loc[subject_id], sampling_rate=256.0)\n",
    "    ep.ecg_process(title=subject_id)\n",
    "    \n",
    "    # save ecg processing result into HR subject dict\n",
    "    dict_hr_subjects[subject_id] = ep.heart_rate\n",
    "    \n",
    "    # compute heart rate variability for each phase separately using EcgProcessor.hrv_patch_process()\n",
    "    hrv_result = ep.hrv_batch_process()\n",
    "    # store HRV results in dictionary\n",
    "    dict_hrv_result[subject_id] = hrv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store and Export Intermediate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create result directories\n",
    "export_path = Path('./results')\n",
    "export_path.mkdir(parents=True, exist_ok=True)\n",
    "ecg_export_path = export_path.joinpath(\"ecg\")\n",
    "ecg_export_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save HR data for separately for each subject\n",
    "for subject_id, dict_subject in dict_hr_subjects.items():\n",
    "    bp.io.ecg.write_hr_subject_dict(dict_subject, ecg_export_path.joinpath(\"hr_result_{}.xlsx\".format(subject_id)))\n",
    "    \n",
    "# alternatively: save it directly after processing the ECG signal in the Section \"Query Data\".\n",
    "# Then you can also directly pass the 'EcgProcessor' instance of the subject to the function:\n",
    "# bp.signals.ecg.io.write_hr_subject_dict(ep, export_path.joinpath(\"hr_result_{}.xlsx\".format(subject_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate and Resample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate (resample) all heart rate values to a sampling rate of 1 Hz (`utils.interpolate_dict_sec()`)  \n",
    "*optional*: If phases are not the same length per subject, they might need to be cut to same length, then use `utils.interpolate_and_cut()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_result = utils.interpolate_dict_sec(dict_hr_subjects)\n",
    "# optional: interpolate and cut in one step\n",
    "dict_result = bp.utils.array_handling.interpolate_and_cut(dict_hr_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Heart Rate data with respect to the mean Heart Rate of the first phase (*Baseline*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result_norm = bp.signals.ecg.normalize_heart_rate(dict_result, normalize_to='Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange the nested dictionary (*HR subject dict*) into a *Phase dict*, i.e. a dictionary with combined heart rate values of all subjects per phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_phase = bp.utils.data_processing.concat_phase_dict(dict_result)\n",
    "dict_phase_norm = bp.utils.data_processing.concat_phase_dict(dict_result_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Result Parameter for Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heart Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp.io.ecg.write_pandas_dict_excel(dict_phase, export_path.joinpath(\"hr_phase_export.xlsx\"))\n",
    "bp.io.ecg.write_pandas_dict_excel(dict_phase_norm, export_path.joinpath(\"hr_phase_export_normalized.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heart Rate Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the HRV result dict into one MultiIndex-DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_result = pd.concat(dict_hrv_result, names=[\"subject\", \"phase\"])\n",
    "\n",
    "hrv_result.to_csv(export_path.joinpath(\"hrv_params.csv\"))\n",
    "# alternatively:\n",
    "# ecg.io.write_result_dict(dict_hrv_result, export_path.joinpath(\"hrv_params.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
